
\section{Preliminaries}

\label{sec:Background}

The computational cost in this paper is analyzed by bounding the number
of arithmetic operations (additions, subtractions, multiplications,
and divisions) in the coefficient field $\mathbb{K}$ on an algebraic
random access machine. We assume the cost of multiplying two polynomial
matrices with dimension $n$ and degree $d$ is $O^{\sim}(n^{\omega}d)$
field operations, where the multiplication exponent $\omega$ is assumed
to satisfy $2<\omega\le3$. We refer to the book by \citet{vonzurgathen}
for more details and reference about the cost of polynomial multiplication
and matrix multiplication.

In the remaining of this section, we provide some of the background
needed in order to understand the basic concepts and tools needed
for nullspace basis computation. This includes basic definitions and
a look at the size of the input and the output for computing such
bases.%
\begin{comment}
, which provide lower bounds for the computational cost 
\end{comment}
{} We also provide a brief introduction to order basis, which is a key
ingredient in our computation. 


\subsection{Order Basis}

Let $\mathbb{K}$ be a field, $\mathbf{F}\in\mathbb{K}\left[\left[x\right]\right]^{m\times n}$
a matrix of power series and $x^{\sigma}$ a non-negative integers. 
\begin{defn}
A vector of polynomials $\mathbf{p}\in\mathbb{K}\left[x\right]^{n\times1}$
has \emph{order} $\left(\mathbf{F},\sigma\right)$ (or \emph{order}
$\sigma$ with respect to $\mathbf{F}$) if $\mathbf{F}\cdot\mathbf{p}\equiv\mathbf{0}\mod x^{\sigma}$,
that is, 
\[
\mathbf{F}\cdot\mathbf{p}=x^{\sigma}\mathbf{r}
\]
 for some $\mathbf{r}\in\mathbb{K}\left[\left[x\right]\right]^{m\times1}$.
\begin{comment}
The vector of power series $\mathbf{r}$ is called the order $\left(\mathbf{F},\sigma\right)$-residual
of \textbf{$\mathbf{p}$}. 
\end{comment}
{} The set of all order $\left(\mathbf{F},\sigma\right)$ vectors is
a $\mathbb{K}\left[x\right]$-module denoted by $\left\langle \left(\mathbf{F},\sigma\right)\right\rangle $. 
\end{defn}
An order basis for $\mathbf{F}$ and $\sigma$ is simply a basis for
the module $\left\langle \left(\mathbf{F},\sigma\right)\right\rangle $.
In this paper we compute those order bases having a type of minimality
degree condition (also referred to as a reduced order basis in \citep{BL1997}).
While minimality is often given in terms of the degrees alone it is
sometimes important to consider this in terms of shifted degrees \citep{BLV:jsc06}.

The shifted column degree of a column polynomial vector $\mathbf{p}$
with shift $\vec{s}=\left[s_{1},\dots,s_{n}\right]\in\mathbb{Z}^{n}$
is given by 
\[
\deg_{\vec{s}}\mathbf{p}=\max_{1\le i\le n}[\deg p^{\left(i\right)}+s_{i}]=\deg(x^{\vec{s}}\cdot\mathbf{p}).
\]
 We call this the \emph{$\vec{s}$-column degree}, or simply the \emph{$\vec{s}$-degree}
of $\mathbf{p}$. A shifted column degree defined this way is equivalent
to the notion of \emph{defect} commonly used in the literature. Our
definition of $\vec{s}$-degree is also equivalent to the notion of
$\mathbf{H}$-degree from \citep{BL1997} for $\mathbf{H}=x^{\vec{s}}$.
As in the uniform shift case, we say a matrix is \emph{$\vec{s}$-column
reduced} or \emph{$\vec{s}$-reduced} if its $\vec{s}$-degrees cannot
be decreased by unimodular column operations. More precisely, if $\mathbf{P}$
is a $\vec{s}$-column reduced and $[d_{1},\dots,d_{n}]$ are the
$\vec{s}$-degrees of columns of $\mathbf{P}$ sorted in nondecreasing
order, then $[d_{1},\dots,d_{n}]$ is lexicographically minimal among
all matrices right equivalent to $\mathbf{P}$. Note that a matrix
$\mathbf{P}$ is $\vec{s}$-column reduced if and only if $x^{\vec{s}}\cdot\mathbf{P}$
is column reduced\citep{BLV:1999,BLV:jsc06}. 

An \emph{order basis} \citep{BeLa94,BL1997} $\mathbf{P}$ of $\mathbf{F}$
with order $\sigma$ and shift $\vec{s}$, or simply an $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis,
is a basis for the module $\left\langle \left(\mathbf{F},\sigma\right)\right\rangle $
\begin{comment}
\[
\left\langle \left(\mathbf{F},\vec{\sigma}\right)\right\rangle =\{\mathbf{p}\in\mathbb{K}\left[x\right]^{n\times1}\|\mathbf{F}\cdot\mathbf{p}=x^{\vec{\sigma}}\mathbf{r},\mathbf{r}\in\mathbb{K}[[x]]^{m\times1}\}
\]
\end{comment}
{} having minimal $\vec{s}$-column degrees.%
\begin{comment}
 If $\vec{\sigma}=\left[\sigma,\dots,\sigma\right]$ are constant
vectors then we simply write $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis.
The precise definition of an $\left(\mathbf{F},\vec{\sigma},\vec{s}\right)$-basis
is as follows.
\end{comment}

\begin{defn}
A polynomial matrix $\mathbf{P}$ is an order basis of $\mathbf{F}$
of order $\sigma$ and shift $\vec{s}$, denoted by $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis,
if the following properties hold:
\begin{enumerate}
\item $\mathbf{P}$ is a nonsingular matrix of dimension $n$.
\item $\mathbf{P}$ is $\vec{s}$-column reduced. 
\item $\mathbf{P}$ has order $\left(\mathbf{F},\sigma\right)$ (or equivalently,
each column of $\mathbf{P}$ is in $\left\langle (\mathbf{F},\sigma)\right\rangle $). 
\item Any $\mathbf{q}\in\left\langle \left(\mathbf{F},\sigma\right)\right\rangle $
can be expressed as a linear combination of the columns of $\mathbf{P}$,
given by $\mathbf{P}^{-1}\mathbf{q}$. 
\end{enumerate}
\end{defn}
Note that the definition of order can be easily extended to having
a different order for each row of $\mathbf{F}\mathbf{P}$ as in \citep{za2009},
but a single uniform order is sufficient for our discussion of minimal
nullspace basis computation in this paper. %
\begin{comment}
The following is a special case of the main result from \citep{BL1997},
a useful result for computing order bases. It can be also easily extended
to compute nullspace basis. We have included a proof for completeness.
\begin{lem}
For an input matrix $\mathbf{F}\in\mathbb{K}\left[x\right]^{m\times n}$,
an order vector $\vec{\sigma}$, and a shift vector $\vec{s}$, if
$\mathbf{P}$ is a $\left(\mathbf{F},\vec{\sigma},\vec{s}\right)$-basis
with $\vec{s}$-column degrees $\vec{t}$, and $\mathbf{Q}$ is a
$(\mathbf{F}\mathbf{P},\vec{\tau},\vec{t})$ -basis with $\vec{t}$-column
degrees $\vec{u}$, where $\vec{\tau}\ge\vec{\sigma}$ component-wise,
then $\mathbf{P}\mathbf{Q}$ is a $(\mathbf{F},\vec{\tau},\vec{s})$-basis
with $\vec{s}$-column degrees $\vec{u}$.\end{lem}
\begin{pf}
It is clear that $\mathbf{P}\mathbf{Q}$ has order $(\mathbf{F},\vec{\tau})$.
We now show that $\mathbf{P}\mathbf{Q}$ is $\vec{s}$-column reduced
and has $\vec{s}$-column degrees $\vec{u}$, or equivalently, $x^{\vec{s}}\mathbf{P}\mathbf{Q}$
is column reduced and has column degrees $\vec{u}$. Notice that $x^{\vec{s}}\mathbf{P}$
has column degrees $\vec{t}$ and a full rank leading column coefficient
matrix $P$. Hence $x^{\vec{s}}\mathbf{P}x^{-\vec{t}}$ has column
degrees $\left[0,\dots0\right]$. Similarly, $x^{\vec{t}}\mathbf{Q}x^{-\vec{u}}$
has column degrees $[0,\dots,0]$ and a full rank leading column coefficient
matrix $Q$. Therefore, $x^{\vec{s}}\mathbf{P}x^{-\vec{t}}x^{\vec{t}}\mathbf{Q}x^{-\vec{u}}=x^{\vec{s}}\mathbf{P}\mathbf{Q}x^{-\vec{u}}$
has column degrees $[0,\dots,0]$ and a full rank leading column coefficient
matrix $PQ$, implying that $x^{\vec{s}}\mathbf{P}\mathbf{Q}$ is
column reduced and that $x^{\vec{s}}\mathbf{P}\mathbf{Q}$ has column
degrees $\vec{u}$, or equivalently, the $\vec{s}$-column degrees
of $\mathbf{PQ}$ is $\vec{u}$.

It remains to show that any $\mathbf{t}\in\left\langle \left(\mathbf{F},\vec{\tau}\right)\right\rangle $
is generated by the columns of $\mathbf{PQ}$. Since $\mathbf{t}\in\left\langle \left(\mathbf{F},\vec{\sigma}\right)\right\rangle $,
it is generated by the $\left(\mathbf{F},\vec{\sigma}\right)$-basis
$\mathbf{P}$, that is, $\mathbf{t}=\mathbf{P}\mathbf{a}$ for $\mathbf{a}=\mathbf{P}^{-1}\mathbf{t}\in\mathbb{K}\left[x\right]^{n}$.
Also, $\mathbf{t}\in\left\langle \left(\mathbf{F},\vec{\tau}\right)\right\rangle $
implies that $\mathbf{a}\in\left\langle \left(\mathbf{FP},\vec{\tau}\right)\right\rangle $
since $\mathbf{F}\mathbf{P}\mathbf{a}=\mathbf{F}\mathbf{t}\equiv0\mod x^{\vec{\tau}}$.
It follows that $\mathbf{a}=\mathbf{Q}\mathbf{b}$ for $\mathbf{b}=\mathbf{Q}^{-1}\mathbf{a}\in\mathbb{K}\left[x\right]^{n}$.
Therefore, $\mathbf{a}=\mathbf{P}^{-1}\mathbf{t}=\mathbf{Q}\mathbf{b}$,
which gives $\mathbf{t}=\mathbf{P}\mathbf{Q}\mathbf{b}$.\end{pf}
\end{comment}


From \citep{BL1997} we have the following lemma. 
\begin{lem}
\label{lem:orderBasisProperty} 

\label{lem:orderBasisEquivalence}The following are equivalent for
a polynomial matrix \textbf{$\mathbf{P}$}: 
\begin{enumerate}
\item $\mathbf{P}$ is a $\left(\mathbf{F},\vec{\sigma},\vec{s}\right)$-basis. 
\item $\mathbf{P}$ is comprised of a set of $n$ minimal $\vec{s}$-degree
polynomial vectors that are linearly independent and each having order
$\left(\mathbf{F},\vec{\sigma}\right)$. 
\item \label{enu:reduced+generator}$\mathbf{P}$ does not contain a zero
column, has order $\left(\mathbf{F},\vec{\sigma}\right)$, is $\vec{s}$-column
reduced, and any $\mathbf{q}\in\left\langle \left(\mathbf{F},\vec{\sigma}\right)\right\rangle $
can be expressed as a linear combination of the columns of $\mathbf{P}$. 
\end{enumerate}
\end{lem}

\subsection{Nullspace Basis}

Nullspace bases are closely related with order bases, as can be seen
from the following definition.
\begin{defn}
A polynomial matrix $\mathbf{N}$ is a $\vec{s}$-minimal nullspace
basis of $\mathbf{F}\in\mathbb{K}\left[x\right]^{m\times n}$ if the
following properties hold:\end{defn}
\begin{enumerate}
\item $\mathbf{N}$ is full-rank.
\item $\mathbf{N}$ is $\vec{s}$-column reduced. 
\item $\mathbf{N}$ satisfies $\mathbf{F}\mathbf{N}=0$.
\item Any $\mathbf{q}\in\mathbb{K}\left[x\right]^{n}$ satisfying $\mathbf{F}\mathbf{q}=0$
can be expressed as a linear combination of the columns of $\mathbf{N}$,
that is, there exists some polynomial vector $\mathbf{a}$ such that
$\mathbf{q}=\mathbf{N}\mathbf{a}$.
\end{enumerate}
\begin{comment}
Note that the module $\left\langle \left(\mathbf{F},\vec{\sigma}\right)\right\rangle $
does not depend on the shift $\vec{s}$. 
\end{comment}


Minimal nullspace bases can be directly computed via order basis computation
using the following fact: If the order $\sigma$ of a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis
$\mathbf{P}$ is high enough, then $\mathbf{P}$ contains a $\vec{s}$-minimal
nullspace basis $\mathbf{N}$. However, this approach may require
the order $\sigma$ to be quite high. For example, if $\mathbf{F}$
has degree $d$ and $\vec{s}$ is uniform, its minimal nullspace bases
can have degree up to $md$, hence the order $\sigma$ need to be
set to $d+md$ in the order basis computation to fully compute a minimal
nullspace basis. Computing such a $\left(\mathbf{F},d+md\right)$-basis
cost $O^{\sim}\left(n^{\omega}\left\lceil m^{2}d/n\right\rceil \right)$
using the algorithm from \citep{za2009}. We can see from this cost
that there is room for improvement when $m$ is large. For example,
in the worst case when $m\in\Theta\left(n\right)$, this cost would
be $O^{\sim}\left(n^{\omega+1}d\right)$. This points to the root
cause for the inefficiency in this approach. Notice that when $m$
is large, the nullspace basis, which can have a column dimension of
$n-m$, is a much smaller subset of the order basis computed. Hence
much effort is put in the computation of order basis elements that
are not part of a nullspace basis. The key to reduce the cost is therefore
to reduce such computation of unneeded order basis elements.
